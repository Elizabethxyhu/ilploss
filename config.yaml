seed_everything: 0
trainer:
  logger: false
  checkpoint_callback: null
  enable_checkpointing: true
  callbacks:
  - class_path: src.callbacks.Timer
  - class_path: src.callbacks.CustomLogging
    init_args:
      rel_filename: training_stats.json
      global_filename: results/knapsack_binary_comboptnet_25.json
  - class_path: pytorch_lightning.callbacks.Timer
    init_args:
      duration: 00:12:00:00
      interval: step
      verbose: true
  - class_path: pytorch_lightning.callbacks.EarlyStopping
    init_args:
      monitor: val/acc/all
      min_delta: 0.0
      patience: 10
      verbose: false
      mode: max
      strict: true
      check_finite: true
      stopping_threshold: 0.999999
      divergence_threshold: null
      check_on_train_epoch_end: null
  - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    init_args:
      logging_interval: step
      log_momentum: false
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      dirpath: null
      filename: best
      monitor: val/acc/all
      verbose: false
      save_last: null
      save_top_k: 1
      save_weights_only: true
      mode: max
      auto_insert_metric_name: true
      every_n_train_steps: null
      train_time_interval: null
      every_n_epochs: null
      save_on_train_epoch_end: null
  - class_path: pytorch_lightning.callbacks.ModelCheckpoint
    init_args:
      dirpath: null
      filename: null
      monitor: null
      verbose: false
      save_last: true
      save_top_k: 1
      save_weights_only: false
      mode: min
      auto_insert_metric_name: true
      every_n_train_steps: null
      train_time_interval: 0:15:00
      every_n_epochs: null
      save_on_train_epoch_end: true
  default_root_dir: null
  gradient_clip_val: null
  gradient_clip_algorithm: null
  process_position: 0
  num_nodes: 1
  num_processes: null
  devices: null
  gpus: 1
  auto_select_gpus: true
  tpu_cores: null
  ipus: null
  log_gpu_memory: null
  progress_bar_refresh_rate: null
  enable_progress_bar: true
  overfit_batches: 0.0
  track_grad_norm: -1
  check_val_every_n_epoch: 1
  fast_dev_run: false
  accumulate_grad_batches: null
  max_epochs: 1000000
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  val_check_interval: null
  flush_logs_every_n_steps: null
  log_every_n_steps: 440
  accelerator: null
  strategy: null
  sync_batchnorm: false
  precision: 16
  enable_model_summary: true
  weights_summary: top
  weights_save_path: null
  num_sanity_val_steps: 0
  resume_from_checkpoint: null
  profiler: null
  benchmark: null
  deterministic: true
  reload_dataloaders_every_n_epochs: 0
  auto_lr_find: false
  replace_sampler_ddp: true
  detect_anomaly: false
  auto_scale_batch_size: false
  prepare_data_per_node: null
  plugins: null
  amp_backend: native
  amp_level: null
  move_metrics_to_cpu: false
  multiple_trainloader_mode: max_size_cycle
  stochastic_weight_avg: false
  terminate_on_nan: null
ckpt_path: null
model_path: runs/neurips/knapsack/binary/comboptnet/items_25/seed_0/version_2/checkpoints/epoch=0-step=295.ckpt
skip_initial_validation: 1
start_val_after_n_epochs: 0
test_only: 1
skip_solve: 0
data:
  class_path: src.datasets.KnapsackDataModule
  init_args:
    data_path: data/knapsack/25.pt
    splits:
      train: 4400
      val: 100
      test: 500
    num_validate_train: 100
    batch_sizes:
      train: 8
      test: 100
      val: 100
    num_workers: 4
model:
  class_path: src.CombOptNet.src.models.DecoderFreeModel
  init_args:
    x_key: x
    y_key: y
    core:
      class_path: src.CombOptNet.src.cores.SolverCore
      init_args:
        encoder:
          class_path: src.encoders.KnapsackEncoder
          init_args:
            backbone_module_params:
              hidden_layer_size: 512
              num_constraints: 4
              embed_dim: 4096
              knapsack_capacity: 1.0
              weight_min: 0.06
              weight_max: 0.14
              cost_min: 0.1
              cost_max: 0.45
              output_nonlinearity: sigmoid
        solver:
          class_path: src.CombOptNet.ext.wrap.CombOptNet
          init_args:
            lb: 0.0
            ub: 1.0
            tau: 0.5
            num_threads: 1
        criterion:
          class_path: torch.nn.L1Loss
          init_args:
            size_average: null
            reduce: null
            reduction: mean
        known_ab_encoder:
          class_path: src.encoders.LUToABEncoder
          init_args:
            lu_encoder:
              class_path: src.encoders.StaticLUEncoder
              init_args:
                num_vars: 25
                lb: -0.5
                ub: 1.5
                batch_size_extractor: src.CombOptNet.src.utils.get_tensor_shape
        cost_train_criterion: null
        cost_loss_wt: 0.0
    solver:
      class_path: src.CombOptNet.src.ilp.CombOptNet
      init_args:
        vtype: I
        env:
          class_path: gurobipy.Env
          init_args:
            logfilename: ''
            empty: false
            params:
              OutputFlag: 0
            cenv: null
            isDefault: false
        num_workers: 10
        show_tqdm: true
        criterion: null
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 0.0005
        weight_decay: 0.0
      custom:
        .*backbone_module.*:
          weight_decay: 0.01
    lr_scheduler:
      class_path: torch.optim.lr_scheduler.ExponentialLR
      init_args:
        gamma: 1.0
    schedulers: {}
    hint: none
    cache_init:
      class_path: torch.nn.init.zeros_
    reset_on_temp_change: false
